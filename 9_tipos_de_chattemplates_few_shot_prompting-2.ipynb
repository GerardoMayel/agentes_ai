{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "xkf7a5mVDKyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e3620f-c164-4d48-d4d7-12779242109e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai langchain"
      ],
      "metadata": {
        "id": "PvfuS1cCDLGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0070be8-933a-4715-9d83-57cde8790f89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "9zEuI4i2DNC9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GsOMu2WTC9LT"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke('Cuanto es 2 🦜 9').content"
      ],
      "metadata": {
        "id": "wkEc1HWtDGXG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "13035647-8552-4d1b-90ca-84c6fc5d632c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Parece que has usado un emoji de loro (🦜) en lugar de un símbolo matemático. Si quieres realizar una operación matemática, por favor aclara qué operación deseas hacer (por ejemplo, suma, resta, multiplicación, etc.).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "examples = [{'input': '2 🦜 2', 'output': '4'},\n",
        "            {'input': '2 🦜 3', 'output': '5'}]"
      ],
      "metadata": {
        "id": "pSQ3VCvLDPR-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = ChatPromptTemplate(\n",
        "    [('human', '{input}'),\n",
        "     ('ai', '{output}')]\n",
        ")"
      ],
      "metadata": {
        "id": "RInJetpwDRzA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples\n",
        ")"
      ],
      "metadata": {
        "id": "ZhzUHUY4DSvX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_prompt.invoke({}).to_messages)"
      ],
      "metadata": {
        "id": "QMqiDubRDUpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa63d69-70b2-485d-bb9f-ae03ed4c5896"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method ChatPromptValue.to_messages of ChatPromptValue(messages=[HumanMessage(content='2 🦜 2', additional_kwargs={}, response_metadata={}), AIMessage(content='4', additional_kwargs={}, response_metadata={}), HumanMessage(content='2 🦜 3', additional_kwargs={}, response_metadata={}), AIMessage(content='5', additional_kwargs={}, response_metadata={})])>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_prompt = ChatPromptTemplate.from_messages(\n",
        "    [('system', 'Eres un mago de las matematicas.'),\n",
        "     few_shot_prompt,\n",
        "     ('human', '{input}')\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "FyVDJCPmDWQ6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = main_prompt | model"
      ],
      "metadata": {
        "id": "yqdnUa5_DX9z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'input': 'Cuanto es 2 🦜 9'}).content"
      ],
      "metadata": {
        "id": "s5VhyRfKDZdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1baa975-efea-4bbd-9430-23e1a842cfe7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El símbolo 🦜 parece estar representando una operación matemática básica, como la suma. Si es así, entonces \\\\(2 🦜 9\\\\) sería igual a \\\\(2 + 9 = 11\\\\). Si este símbolo representa otra operación, por favor aclara su significado.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Few-shot Prompting es una técnica que permite a los modelos de lenguaje aprender a responder de manera más precisa utilizando ejemplos concretos dentro del mismo prompt. Los ejemplos ayudan a guiar las respuestas del modelo, mejorando su relevancia. Hay dos formas de implementar esta técnica: usando ejemplos fijos o dinámicos, lo que permite adaptar las interacciones según la entrada.\n",
        "\n",
        "Conceptos Principales:\n",
        "\n",
        "Few-shot Prompting: Utiliza ejemplos dentro del prompt para enseñar al modelo cómo debe comportarse. Los ejemplos actúan como guías para que el modelo aprenda a responder de manera precisa.\n",
        "Ejemplo: Si queremos que el modelo interprete emojis como operaciones matemáticas, proporcionamos ejemplos como \"2 🦜 2 = 4\" para que el modelo aprenda la relación.\n",
        "Ejemplos Fijos: Conjunto estático de ejemplos que se utilizan en cada interacción, independientemente de la entrada del usuario.\n",
        "Ejemplo: Siempre usar \"2 🦜 2 = 4\" y \"2 🦜 3 = 5\" para que el modelo entienda cómo operar con emojis.\n",
        "Ejemplos Dinámicos: Los ejemplos se seleccionan según la similitud semántica entre la entrada del usuario y los ejemplos almacenados.\n",
        "Ejemplo: Si el usuario pregunta \"¿cuánto es 5 emoji 5?\", se selecciona un ejemplo similar para que el modelo aprenda a sumar usando emojis.\n",
        "Prompt Template: Pasa ejemplos al modelo. Cada ejemplo tiene una entrada (input) y una salida (output) esperada, generalmente estructurados en formato de diccionario.\n",
        "Ejemplo: Un diccionario con {input: \"2 🦜 2\", output: \"4\"} enseña al modelo que el emoji representa una operación matemática.\n",
        "Chains: Permite integrar múltiples pasos en una cadena, combinando el modelo con ejemplos y roles para crear interacciones más complejas.\n",
        "Ejemplo: Encadenar un prompt que define al modelo como \"un mago de las matemáticas\" junto con ejemplos para que se comporte de acuerdo a la expectativa.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IqDdAdYBfG8w"
      }
    }
  ]
}