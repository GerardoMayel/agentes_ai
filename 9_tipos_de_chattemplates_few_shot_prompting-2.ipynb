{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "if \"OPENAI_API_KEY\" not in os.environ:\n",
        "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
      ],
      "metadata": {
        "id": "xkf7a5mVDKyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e3620f-c164-4d48-d4d7-12779242109e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: 路路路路路路路路路路\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-openai langchain"
      ],
      "metadata": {
        "id": "PvfuS1cCDLGS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0070be8-933a-4715-9d83-57cde8790f89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m49.9/49.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m408.0/408.0 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m296.9/296.9 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m386.9/386.9 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m78.0/78.0 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m325.2/325.2 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "9zEuI4i2DNC9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GsOMu2WTC9LT"
      },
      "outputs": [],
      "source": [
        "model = ChatOpenAI(model=\"gpt-4o\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.invoke('Cuanto es 2  9').content"
      ],
      "metadata": {
        "id": "wkEc1HWtDGXG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "13035647-8552-4d1b-90ca-84c6fc5d632c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Parece que has usado un emoji de loro () en lugar de un s铆mbolo matem谩tico. Si quieres realizar una operaci贸n matem谩tica, por favor aclara qu茅 operaci贸n deseas hacer (por ejemplo, suma, resta, multiplicaci贸n, etc.).'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "\n",
        "examples = [{'input': '2  2', 'output': '4'},\n",
        "            {'input': '2  3', 'output': '5'}]"
      ],
      "metadata": {
        "id": "pSQ3VCvLDPR-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_prompt = ChatPromptTemplate(\n",
        "    [('human', '{input}'),\n",
        "     ('ai', '{output}')]\n",
        ")"
      ],
      "metadata": {
        "id": "RInJetpwDRzA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples\n",
        ")"
      ],
      "metadata": {
        "id": "ZhzUHUY4DSvX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(few_shot_prompt.invoke({}).to_messages)"
      ],
      "metadata": {
        "id": "QMqiDubRDUpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aa63d69-70b2-485d-bb9f-ae03ed4c5896"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method ChatPromptValue.to_messages of ChatPromptValue(messages=[HumanMessage(content='2  2', additional_kwargs={}, response_metadata={}), AIMessage(content='4', additional_kwargs={}, response_metadata={}), HumanMessage(content='2  3', additional_kwargs={}, response_metadata={}), AIMessage(content='5', additional_kwargs={}, response_metadata={})])>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_prompt = ChatPromptTemplate.from_messages(\n",
        "    [('system', 'Eres un mago de las matematicas.'),\n",
        "     few_shot_prompt,\n",
        "     ('human', '{input}')\n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "FyVDJCPmDWQ6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = main_prompt | model"
      ],
      "metadata": {
        "id": "yqdnUa5_DX9z"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain.invoke({'input': 'Cuanto es 2  9'}).content"
      ],
      "metadata": {
        "id": "s5VhyRfKDZdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b1baa975-efea-4bbd-9430-23e1a842cfe7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'El s铆mbolo  parece estar representando una operaci贸n matem谩tica b谩sica, como la suma. Si es as铆, entonces \\\\(2  9\\\\) ser铆a igual a \\\\(2 + 9 = 11\\\\). Si este s铆mbolo representa otra operaci贸n, por favor aclara su significado.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Few-shot Prompting es una t茅cnica que permite a los modelos de lenguaje aprender a responder de manera m谩s precisa utilizando ejemplos concretos dentro del mismo prompt. Los ejemplos ayudan a guiar las respuestas del modelo, mejorando su relevancia. Hay dos formas de implementar esta t茅cnica: usando ejemplos fijos o din谩micos, lo que permite adaptar las interacciones seg煤n la entrada.\n",
        "\n",
        "Conceptos Principales:\n",
        "\n",
        "Few-shot Prompting: Utiliza ejemplos dentro del prompt para ense帽ar al modelo c贸mo debe comportarse. Los ejemplos act煤an como gu铆as para que el modelo aprenda a responder de manera precisa.\n",
        "Ejemplo: Si queremos que el modelo interprete emojis como operaciones matem谩ticas, proporcionamos ejemplos como \"2  2 = 4\" para que el modelo aprenda la relaci贸n.\n",
        "Ejemplos Fijos: Conjunto est谩tico de ejemplos que se utilizan en cada interacci贸n, independientemente de la entrada del usuario.\n",
        "Ejemplo: Siempre usar \"2  2 = 4\" y \"2  3 = 5\" para que el modelo entienda c贸mo operar con emojis.\n",
        "Ejemplos Din谩micos: Los ejemplos se seleccionan seg煤n la similitud sem谩ntica entre la entrada del usuario y los ejemplos almacenados.\n",
        "Ejemplo: Si el usuario pregunta \"驴cu谩nto es 5 emoji 5?\", se selecciona un ejemplo similar para que el modelo aprenda a sumar usando emojis.\n",
        "Prompt Template: Pasa ejemplos al modelo. Cada ejemplo tiene una entrada (input) y una salida (output) esperada, generalmente estructurados en formato de diccionario.\n",
        "Ejemplo: Un diccionario con {input: \"2  2\", output: \"4\"} ense帽a al modelo que el emoji representa una operaci贸n matem谩tica.\n",
        "Chains: Permite integrar m煤ltiples pasos en una cadena, combinando el modelo con ejemplos y roles para crear interacciones m谩s complejas.\n",
        "Ejemplo: Encadenar un prompt que define al modelo como \"un mago de las matem谩ticas\" junto con ejemplos para que se comporte de acuerdo a la expectativa.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IqDdAdYBfG8w"
      }
    }
  ]
}